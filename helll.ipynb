{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWQlU44wHovFwbKCqJmgSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/444vj/child-malnutrition-01/blob/main/helll.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcQwx2RZZbXZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "import os\n",
        "import glob\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers.core import Dense\n",
        "# from keras.optimizers import SGD\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "import tensorflow as tf\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_X_y(data):\n",
        "  X = data.drop('H/A',axis = 1)\n",
        "  X = X.drop('W/A',axis = 1)\n",
        "  X = X.drop('W/H',axis = 1)\n",
        "  X = X.drop('Bmi',axis = 1)\n",
        "  X = X.drop('HAWH',axis = 1)\n",
        "  y1 = data['W/A']\n",
        "  y2 = data['H/A']\n",
        "  y3 = data['W/H']\n",
        "  y4 = data['Bmi']\n",
        "  y5 = data['HAWH']\n",
        "  y1 = y1.to_frame()  # convert y outputs from series to dataframe\n",
        "  y2 = y2.to_frame()\n",
        "  y3 = y3.to_frame()\n",
        "  y4 = y4.to_frame()\n",
        "  print(X.shape, 'X shape')\n",
        "  print(y1.shape, 'y1 shape')\n",
        "  print(y2.shape, 'y2 shape')\n",
        "  print(y3.shape, 'y3 shape')\n",
        "  print(y4.shape, 'y4 shape')\n",
        "  print(y5.shape, 'y5 shape')\n",
        "  return X, y1, y2, y3, y4, y5"
      ],
      "metadata": {
        "id": "kX0OE8NvZklJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(data):\n",
        "  _data = pd.DataFrame(columns=data.columns)\n",
        "  for c in data.columns:           #Normalization of Data\n",
        "    min = data[c].min()\n",
        "    max = data[c].max()\n",
        "    _data[c] = (data[c] - min)/(max - min)\n",
        "    # _data = data\n",
        "  print(_data.head())\n",
        "  return _data"
      ],
      "metadata": {
        "id": "lTaNtsqHZmgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_accuracy(pred, y_test):\n",
        "  a = np.argmax(pred, axis = 1)\n",
        "  accuracy = []\n",
        "  count = 0\n",
        "  for i,c in enumerate(y_test):\n",
        "    if c == a[i]:\n",
        "      accuracy.append(1)\n",
        "      count += 1\n",
        "    else:\n",
        "      accuracy.append(0)\n",
        "  print('accuracy', count/len(accuracy))\n",
        "  return count/len(accuracy)\n",
        ""
      ],
      "metadata": {
        "id": "LkT9In6vZoIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.drop(['Unnamed: 0.1'], axis = 1)\n",
        "\n",
        "\n",
        "df\n",
        ""
      ],
      "metadata": {
        "id": "6H6YtN6PZp5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfl = pd.DataFrame()\n",
        "\n",
        "\n",
        "\n",
        "dfl"
      ],
      "metadata": {
        "id": "gUuKebBIZtJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfd = pd.get_dummies(df)\n",
        "\n",
        "\n",
        "dfd"
      ],
      "metadata": {
        "id": "781qECHIZxSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfh = pd.DataFrame()"
      ],
      "metadata": {
        "id": "ZAvcqJmEZzOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfh.to_csv('Dataset_5-6_top15.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "dnhjXP_2Z0ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfhd = pd.get_dummies(dfh)\n",
        ""
      ],
      "metadata": {
        "id": "-V0WbqmqZ1yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfch['caste']= df['caste']\n",
        "dfch['state']= df['state']\n",
        "dfch['area']= df['area']\n",
        "dfch['father\\'s education']= df['father\\'s education']\n",
        "dfch['father\\'s occupation']= df['father\\'s occupation']\n",
        "dfch['mother\\'s education']= df['mother\\'s education']\n",
        "dfch['mother\\'s occupation']= df['mother\\'s occupation']\n",
        "dfch['exposure to mass media']= df['exposure to mass media']\n",
        "dfch['Toilet Facility'] = df['Toilet Facility']\n",
        "dfch['mother\\'s age']= df['mother\\'s age']\n",
        "dfch['mother\\'s bmi']= df['mother\\'s bmi']\n",
        "dfch['child\\'s age']= df['child\\'s age']\n",
        "dfch['birth weight']= df['birth weight']\n",
        "dfch['wealth index']= df['wealth index']\n",
        "dfch['H/A'] = df['H/A']\n",
        "dfch['W/A'] = df['W/A']\n",
        "dfch['W/H'] = df['W/H']\n",
        "dfch['Bmi'] = df['Bmi']\n",
        "dfch['HAWH'] = df['HAWH']\n",
        "dfch['no of living children'] = df['no of living children']\n",
        "dfch['immunization']= df['immunization']\n",
        "# dfch = dfch.drop(['type of family'], axis = 1)"
      ],
      "metadata": {
        "id": "fBNP1H8PZ4Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dfch.shape\n"
      ],
      "metadata": {
        "id": "qAdf_GZ4Z7rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfch.to_csv('Dataset_5-6_chi16.csv')\n",
        ""
      ],
      "metadata": {
        "id": "IXlXkr-KZ9S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfchd = pd.get_dummies(dfch)\n",
        ""
      ],
      "metadata": {
        "id": "H-9Oe4qlZ-gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfchd\n"
      ],
      "metadata": {
        "id": "YMaZArHxaAQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corrmat = dfl.corr()\n",
        "top_corr_features = corrmat.index\n",
        "plt.figure(figsize=(50,50))\n",
        "#plot heat map\n",
        "g=sns.heatmap(dfl[top_corr_features].corr(),annot=True,cmap=\"gist_earth\")\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "tcQGVhY-aCnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1, a, b, c, d= split_X_y(dfd)"
      ],
      "metadata": {
        "id": "nZ23j5FoaERC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_35 = PCA(n_components=35, random_state= 574)\n",
        "pca_35.fit(X1)\n",
        "print('variance explained by 35 components is' , sum(pca_35.explained_variance_ratio_*100))\n",
        "\n"
      ],
      "metadata": {
        "id": "KfyZmA0jaG3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_16 = PCA(n_components=16, random_state= 52)\n",
        "pca_16.fit(X1)\n",
        "print('variance explained by 16 components is' , sum(pca_16.explained_variance_ratio_*100))\n",
        ""
      ],
      "metadata": {
        "id": "GFMhcErjaJsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.cumsum(pca_16.explained_variance_ratio_*100)"
      ],
      "metadata": {
        "id": "5xwusx70aLA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.plot(np.cumsum(pca_35.explained_variance_ratio_*100))\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Explained Variance')\n",
        "plt.savefig('elbow_plot.png', dpi = 100)"
      ],
      "metadata": {
        "id": "HEXDUZl8aMuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pca_35.explained_variance_ratio_*100"
      ],
      "metadata": {
        "id": "qFfpiHxwaPbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# pca_n95 = PCA(n_components=0.95, random_state= 359)\n",
        "# pca_n95.fit(X1)\n",
        "X_pca_35 = pca_35.transform(X1)\n",
        ""
      ],
      "metadata": {
        "id": "rBo7XmJ_aQwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pca_35.shape\n",
        ""
      ],
      "metadata": {
        "id": "CMHYjB6caSZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pca_35"
      ],
      "metadata": {
        "id": "mozmM3gBaTvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfl = dfl.astype(float)\n",
        "dfd = dfd.astype(float)\n",
        "\n"
      ],
      "metadata": {
        "id": "kMQXmiWqaVVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['religion'].hist(bins=20);"
      ],
      "metadata": {
        "id": "3c44uN7OaWtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pca = pd.DataFrame(X_pca_35, columns = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16',\n",
        "                                           'PC17', 'PC18', 'PC19', 'PC20', 'PC21', 'PC22', 'PC23', 'PC24', 'PC25', 'PC26', 'PC27', 'PC28', 'PC29', 'PC30', 'PC31',\n",
        "                                           'PC32', 'PC33', 'PC34', 'PC35'])\n",
        "df_pca['H/A'] = df['H/A']\n",
        "df_pca['W/A'] = df['W/A']\n",
        "df_pca['W/H'] = df['W/H']\n",
        "df_pca['Bmi'] = df['Bmi']"
      ],
      "metadata": {
        "id": "LmlFjiEFaYMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pca.shape"
      ],
      "metadata": {
        "id": "ZoZVaBhMaZ_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pca"
      ],
      "metadata": {
        "id": "rSvbLsosabtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train, test = train_test_split(dfchd, test_size=0.15, random_state = 13)\n",
        "train, val = train_test_split(Train, test_size=0.15, random_state = 59)"
      ],
      "metadata": {
        "id": "wwAEx83Radyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape, ' is the shape of training data for NN')\n",
        "print(Train.shape, ' is the shape of training data for ML algos')\n",
        "print(test.shape, ' is the shape of testing data')\n",
        "print(val.shape, ' is the shape of validation data')"
      ],
      "metadata": {
        "id": "LcDCJx2tafNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_Train, y1_Train, y2_Train, y3_Train, y4_Train, y5_Train = split_X_y(Train)\n",
        "\n"
      ],
      "metadata": {
        "id": "UUQ1OqMRagpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y1_test, y2_test, y3_test, y4_test, y5_test= split_X_y(test)\n",
        ""
      ],
      "metadata": {
        "id": "74fu9GBVah9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val, y1_val, y2_val, y3_val, y4_val, y5_val = split_X_y(val)\n",
        ""
      ],
      "metadata": {
        "id": "7ViXmF3CajUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y1_train, y2_train, y3_train, y4_train, y5_train = split_X_y(train)\n",
        ""
      ],
      "metadata": {
        "id": "Hwzl_DMxakql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_X_Train = norm(X_Train)\n",
        "_X_train = norm(X_train)\n",
        "_X_val = norm(X_val)\n",
        "_X_test = norm(X_test)\n",
        ""
      ],
      "metadata": {
        "id": "fBZcEIAyamQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y1_Train.shape"
      ],
      "metadata": {
        "id": "EgxWCCTWanyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Train_pca, test_pca = train_test_split(df_pca, test_size=0.2, random_state = 368)\n",
        "train_pca, val_pca = train_test_split(Train_pca, test_size=0.15, random_state = 40)\n",
        ""
      ],
      "metadata": {
        "id": "7td6N868apRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(train_pca.shape, ' is the shape of training data for NN')\n",
        "print(Train_pca.shape, ' is the shape of training data for ML algos')\n",
        "print(test_pca.shape, ' is the shape of testing data')\n",
        "print(val_pca.shape, ' is the shape of validation data')\n",
        ""
      ],
      "metadata": {
        "id": "BysVzSp3aqic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_Train_pca, y1_Train_pca, y2_Train_pca, y3_Train_pca, y4_Train_pca = split_X_y(Train_pca)\n",
        ""
      ],
      "metadata": {
        "id": "tGGnXFZJar8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test_pca, y1_test_pca, y2_test_pca, y3_test_pca, y4_test_pca = split_X_y(test_pca)\n",
        ""
      ],
      "metadata": {
        "id": "XFc5Nkcwat0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_val_pca, y1_val_pca, y2_val_pca, y3_val_pca, y4_val_pca = split_X_y(val_pca)\n",
        ""
      ],
      "metadata": {
        "id": "3RH2xr6Favqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train_pca, y1_train_pca, y2_train_pca, y3_train_pca, y4_train_pca = split_X_y(train_pca)\n",
        "\n"
      ],
      "metadata": {
        "id": "_QM11UFbaw9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "_X_Train_pca = norm(X_Train_pca)\n",
        "_X_train_pca = norm(X_train_pca)\n",
        "_X_val_pca = norm(X_val_pca)\n",
        "_X_test_pca = norm(X_test_pca)"
      ],
      "metadata": {
        "id": "b1HMnZggayTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def base_model_pca(inputs):\n",
        "    x = tf.keras.layers.Dense(1024, activation= tf.nn.relu)(inputs)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    x = tf.keras.layers.Dense(1024, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dense(512, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(512, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dense(64, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(64, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dense(32, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(16, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(8, activation= tf.nn.relu)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "TmLV3kmja0XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_model_pca(inputs):\n",
        "\n",
        "    # get the base model\n",
        "    x = base_model_pca(inputs)\n",
        "\n",
        "    # connect the output Dense layer for classification. this will use a sigmoid activation.\n",
        "    wa = Dense(units='2', activation='sigmoid', name = 'W/A')(x)\n",
        "    ha = Dense(units='2', activation='sigmoid', name='H/A')(x)\n",
        "    wh = Dense(units='2', activation='sigmoid', name='W/H')(x)\n",
        "    bmi = Dense(units='2', activation='sigmoid', name='Bmi')(x)\n",
        "\n",
        "    # define the model using the input and output layers\n",
        "    model = Model(inputs=inputs, outputs=[wa, ha, wh, bmi])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "CIlLb_Vna2Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs = tf.keras.layers.Input(shape=(25,))\n",
        "inputs= Input(shape=(len(_X_train_pca.columns,)), name='inputs')\n",
        "print(type(inputs))\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0008)\n",
        "model_pca = final_model_pca(inputs)\n",
        "\n",
        "model_pca.compile(optimizer=adam,\n",
        "              loss = {'W/A' : 'binary_crossentropy',\n",
        "                      'H/A' : 'binary_crossentropy',\n",
        "                      'W/H' : 'binary_crossentropy',\n",
        "                      'Bmi' : 'binary_crossentropy'\n",
        "                     },\n",
        "              metrics = {'W/A' : 'accuracy',\n",
        "                         'H/A' : 'accuracy',\n",
        "                         'W/H' : 'accuracy',\n",
        "                         'Bmi' : 'accuracy'\n",
        "                       }\n",
        "             )"
      ],
      "metadata": {
        "id": "WDT5lYtaa3_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "_X_train_pca_np = _X_train_pca.to_numpy()\n",
        "_X_test_pca_np = _X_test_pca.to_numpy()\n",
        "_X_Train_pca_np = _X_Train_pca.to_numpy()\n",
        "_X_val_pca_np = _X_val_pca.to_numpy()\n",
        ""
      ],
      "metadata": {
        "id": "QsryCEIGa5ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y1_train_pca_oh = to_categorical(y1_train_pca, 2)\n",
        "y2_train_pca_oh = to_categorical(y2_train_pca, 2)\n",
        "y3_train_pca_oh = to_categorical(y3_train_pca, 2)\n",
        "y4_train_pca_oh = to_categorical(y4_train_pca, 2)\n",
        ""
      ],
      "metadata": {
        "id": "uWkiMM1Ma63t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y1_val_pca_oh = to_categorical(y1_val_pca, 2)\n",
        "y2_val_pca_oh = to_categorical(y2_val_pca, 2)\n",
        "y3_val_pca_oh = to_categorical(y3_val_pca, 2)\n",
        "y4_val_pca_oh = to_categorical(y4_val_pca, 2)\n",
        "\n"
      ],
      "metadata": {
        "id": "G0z50djXa8Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pca.summary()"
      ],
      "metadata": {
        "id": "Tchc96bxa9qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model for 2000 epochs\n",
        "history_pca = model_pca.fit(_X_train_pca_np, [y1_train_pca_oh, y2_train_pca_oh, y3_train_pca_oh, y4_train_pca_oh],\n",
        "                    epochs=15, batch_size=64,\n",
        "                    validation_data=(_X_val_pca_np, [y1_val_pca_oh, y2_val_pca_oh, y3_val_pca_oh, y4_val_pca_oh]),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "VjnGU9fabBAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred1, pred2, pred3, pred4 = model_pca.predict(_X_test_pca_np)"
      ],
      "metadata": {
        "id": "BpjBksOubDS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y1_test_pca_np = y1_test_pca.to_numpy()\n",
        "y2_test_pca_np = y2_test_pca.to_numpy()\n",
        "y3_test_pca_np = y3_test_pca.to_numpy()\n",
        "y4_test_pca_np = y4_test_pca.to_numpy()"
      ],
      "metadata": {
        "id": "VNGxp4cbbFHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WA_accuracy = get_accuracy(pred1, y1_test_pca_np)"
      ],
      "metadata": {
        "id": "PmBx5tHgbGfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HA_accuracy = get_accuracy(pred2, y2_test_pca_np)\n",
        ""
      ],
      "metadata": {
        "id": "habfoG_7bHwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WA_accuracy = get_accuracy(pred3, y3_test_pca_np)\n",
        ""
      ],
      "metadata": {
        "id": "jakpZOTubI68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Bmi_accuracy = get_accuracy(pred4, y4_test_pca_np)\n",
        ""
      ],
      "metadata": {
        "id": "SAN4zcxbbKCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_pca.save('/content/results/pca_nn1.h5')\n",
        "\n"
      ],
      "metadata": {
        "id": "9Aord_LIbLY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def base_model(inputs):\n",
        "    x = tf.keras.layers.Dense(1024, activation= tf.nn.relu)(inputs)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    x = tf.keras.layers.Dense(1024, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dense(512, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(512, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dense(64, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(64, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dense(32, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(16, activation= tf.nn.relu)(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(8, activation= tf.nn.relu)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "cvjtL4zXbNEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_model(inputs):\n",
        "\n",
        "    # get the base model\n",
        "    x = base_model(inputs)\n",
        "\n",
        "    # connect the output Dense layer for classification. this will use a sigmoid activation.\n",
        "    wa = Dense(units='2', activation='sigmoid', name = 'W/A')(x)\n",
        "    ha = Dense(units='2', activation='sigmoid', name='H/A')(x)\n",
        "    wh = Dense(units='2', activation='sigmoid', name='W/H')(x)\n",
        "    bmi = Dense(units='2', activation='sigmoid', name='Bmi')(x)\n",
        "    hawh = Dense(units='2', activation='sigmoid', name='HAWH')(x)\n",
        "    # mal = Dense(units = '4', activation = 'softmax', name = 'Mal')(x)\n",
        "\n",
        "    # define the model using the input and output layers\n",
        "    model = Model(inputs=inputs, outputs=[wa, ha, wh, bmi, hawh])\n",
        "    # model = Model(inputs = inputs, outputs = [mal])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "kt09EBsSbOwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()"
      ],
      "metadata": {
        "id": "X8Pre3L_bRxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs = tf.keras.layers.Input(shape=(25,))\n",
        "inputs= Input(shape=(len(_X_train.columns,)), name='inputs')\n",
        "print(type(inputs))\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0009)\n",
        "model = final_model(inputs)\n",
        "\n",
        "model.compile(optimizer=adam,\n",
        "              loss = {'W/A' : 'binary_crossentropy',\n",
        "                      'H/A' : 'binary_crossentropy',\n",
        "                      'W/H' : 'binary_crossentropy',\n",
        "                      'Bmi' : 'binary_crossentropy',\n",
        "                      'HAWH' : 'binary_crossentropy'\n",
        "                     },\n",
        "              metrics = {'W/A' : ['accuracy', tf.keras.metrics.AUC()],\n",
        "                         'H/A' : ['accuracy', tf.keras.metrics.AUC()],\n",
        "                         'W/H' : ['accuracy', tf.keras.metrics.AUC()],\n",
        "                         'Bmi' : ['accuracy', tf.keras.metrics.AUC()],\n",
        "                         'HAWH' : ['accuracy', tf.keras.metrics.AUC()]\n",
        "                       }\n",
        "             )\n",
        "# model.compile(optimizer = adam, loss = {'Mal':'categorical_crossentropy'}, metrics = {'Mal':'accuracy'})\n",
        "\n"
      ],
      "metadata": {
        "id": "rk_xIvU9bT0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "_X_train_np = _X_train.to_numpy()\n",
        "_X_test_np = _X_test.to_numpy()\n",
        "_X_val_np = _X_val.to_numpy()\n",
        ""
      ],
      "metadata": {
        "id": "5JWTAc62bVQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1_train_oh = to_categorical(y1_train, 2)\n",
        "y2_train_oh = to_categorical(y2_train, 2)\n",
        "y3_train_oh = to_categorical(y3_train, 2)\n",
        "y4_train_oh = to_categorical(y4_train, 2)\n",
        "# y_train_oh = to_categorical(y_train, 4)\n",
        "y5_train_oh = to_categorical(y5_train, 2)"
      ],
      "metadata": {
        "id": "Z4973j_-bWkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y1_val_oh = to_categorical(y1_val, 2)\n",
        "y2_val_oh = to_categorical(y2_val, 2)\n",
        "y3_val_oh = to_categorical(y3_val, 2)\n",
        "y4_val_oh = to_categorical(y4_val, 2)\n",
        "y5_val_oh = to_categorical(y5_val, 2)\n",
        "\n",
        "# y_val_oh = to_categorical(y_val, 4)"
      ],
      "metadata": {
        "id": "u6EJdZEvbYQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "p6gTOzAWbZk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = '/content/results/chi16_nn2.h5'"
      ],
      "metadata": {
        "id": "vCQ68O8sbbfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     filepath=checkpoint_filepath,\n",
        "#     save_weights_only=True,\n",
        "#     monitor='val_H/A_accuracy',\n",
        "#     mode='max',\n",
        "#     save_best_only=True)\n",
        ""
      ],
      "metadata": {
        "id": "VovNEDarbdCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train the model for 2000 epochs\n",
        "history = model.fit(_X_train_np, [y1_train_oh, y2_train_oh, y3_train_oh, y4_train_oh, y5_train_oh],\n",
        "                    epochs=20, batch_size=64,\n",
        "                    validation_data=(_X_val_np, [y1_val_oh, y2_val_oh, y3_val_oh, y4_val_oh, y5_val_oh]),\n",
        "                    verbose=1)\n",
        "# history = model.fit(_X_train_np, y_train_oh, epochs=100, batch_size=64, validation_data=(_X_val_np, y_val_oh), verbose=1)\n",
        ""
      ],
      "metadata": {
        "id": "pEwsoL9nbezC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictions1, predictions2, predictions3, predictions4, predictions5 = model.predict(_X_test_np)\n",
        "# predictions = model.predict(_X_test_np)\n",
        ""
      ],
      "metadata": {
        "id": "ls5637m5bhqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y1_test_np = y1_test.to_numpy()\n",
        "y2_test_np = y2_test.to_numpy()\n",
        "y3_test_np = y3_test.to_numpy()\n",
        "y4_test_np = y4_test.to_numpy()\n",
        "y5_test_np = y5_test.to_numpy()\n",
        "# y_test_np = y_test.to_numpy()"
      ],
      "metadata": {
        "id": "qzLx1HPGbjUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "WA_accuracy = get_accuracy(predictions1, y1_test_np)"
      ],
      "metadata": {
        "id": "XtThfh37bkij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "HA_accuracy = get_accuracy(predictions2, y2_test_np)"
      ],
      "metadata": {
        "id": "lg9vrzw1blxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "WH_accuracy = get_accuracy(predictions3, y3_test_np)\n",
        ""
      ],
      "metadata": {
        "id": "Z60ftgPQbnEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Bmi_accuracy = get_accuracy(predictions4, y4_test_np)"
      ],
      "metadata": {
        "id": "1dM3DpaSbocX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "HAWH_accuracy = get_accuracy(predictions5, y5_test_np)"
      ],
      "metadata": {
        "id": "1eDhQp0obpkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# model.load_weights('/content/results/chi16_nn1.h5')"
      ],
      "metadata": {
        "id": "YLpHISy0bq_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.save('/content/results/chi16_nn1.h5')"
      ],
      "metadata": {
        "id": "724StuGRbsbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sklearn\n",
        "from sklearn.feature_selection import RFE\n",
        "# define the method\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=3)\n",
        "# fit the model\n",
        "rfe.fit(_X_Train, y1_Train)\n",
        "# transform the data\n",
        "X, y = rfe.transform(_X_Train, y1_Train)"
      ],
      "metadata": {
        "id": "5rEhpeTVbt68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate RFE for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "# define dataset\n",
        "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "# create pipeline\n",
        "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=10)\n",
        "model = DecisionTreeClassifier()\n",
        "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(pipeline, _X_Train, y1_Train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "id": "Mr8zGYpmbv8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "start = time.time()\n",
        "knn = KNeighborsClassifier(n_neighbors = 50 ).fit(_X_Train, y1_Train)\n",
        "\n",
        "# accuracy on X_test\n",
        "accuracy = knn.score(_X_Test, y1_Test)\n",
        "end = time.time()\n",
        "print(end-start, 'seconds')\n",
        "print (f'Accuracy of Knn on variable y1 is {accuracy}')\n",
        ""
      ],
      "metadata": {
        "id": "t5KfzOGFbx10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = []\n",
        "for i in range(1,50):\n",
        "  knn = KNeighborsClassifier(n_neighbors = i).fit(_X_Train, y1_Train)\n",
        "  knn_accuracy = knn.score(_X_Test, y1_Test)\n",
        "  accuracy.append(knn_accuracy)\n",
        "plt.plot(np.arange(1,50), accuracy, '-o')"
      ],
      "metadata": {
        "id": "mKod9NKTbzJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "start = time.time()\n",
        "svm_model_linear = SVC(kernel = 'rbf', C = 25).fit(_X_Train, y1_Train)\n",
        "svm_predictions = svm_model_linear.predict(_X_Test)\n",
        "\n",
        "# model accuracy for X_test\n",
        "accuracy = svm_model_linear.score(_X_Test, y1_Test)\n",
        "end = time.time()\n",
        "print(end - start, 'seconds')\n",
        "print('accuracy of SVM is', accuracy)\n",
        ""
      ],
      "metadata": {
        "id": "v1qSgcW0b0ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# accuracy = []\n",
        "# for i in range(1,50):\n",
        "#   svm_model_linear = SVC(kernel = 'rbf', C = i).fit(_X_Train, y1_Train)\n",
        "#   svm_predictions = svm_model_linear.predict(_X_Test)\n",
        "#   svm_accuracy = svm_model_linear.score(_X_Test, y1_Test)\n",
        "#   accuracy.append(svm_accuracy)\n",
        "# plt.plot(np.arange(1,50), accuracy, '-o')"
      ],
      "metadata": {
        "id": "e_k8SiXkb2hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "start = time.time()\n",
        "dtree_model = DecisionTreeClassifier(max_depth = 5).fit(_X_Train, y1_Train)\n",
        "dtree_predictions = dtree_model.predict(_X_Test)\n",
        "end = time.time()\n",
        "print(end - start, 'seconds')\n",
        "print(dtree_model.score(_X_Test, y1_Test))\n",
        "\n",
        "# creating a confusion matrix\n",
        "cm = confusion_matrix(y1_Test, dtree_predictions)"
      ],
      "metadata": {
        "id": "0hyIFOYRb4TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relation_graph(max_depth):\n",
        "  dtree_model = DecisionTreeClassifier(max_depth = max_depth).fit(_X_Train, y1_Train)\n",
        "  dtree_predictions = dtree_model.predict(_X_Test)\n",
        "  dtree_accuracy = []\n",
        "  count = 0\n",
        "  for i,c in enumerate(y1_Test):\n",
        "      if c == dtree_predictions[i]:\n",
        "        dtree_accuracy.append(1)\n",
        "        count += 1\n",
        "      else:\n",
        "        dtree_accuracy.append(0)\n",
        "  print('decision_tree_accuracy', count/len(dtree_accuracy))\n",
        "  return (count/len(dtree_accuracy))"
      ],
      "metadata": {
        "id": "GjlEBfTHb6AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_X_Test.shape"
      ],
      "metadata": {
        "id": "RbwxNqosb7aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy= []\n",
        "for i in range(2,50):\n",
        "  a = relation_graph(i)\n",
        "  accuracy.append(a)\n",
        "plt.plot(np.arange(2,50,1), accuracy, '-o')"
      ],
      "metadata": {
        "id": "6lSSrlPIb8wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instantiate the model (using the default parameters)\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(_X_Train,y1_Train)\n",
        "\n",
        "#\n",
        "y_pred=logreg.predict(_X_Test)"
      ],
      "metadata": {
        "id": "-bWA_Lx5cA43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "# from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y1_Test, y_pred))"
      ],
      "metadata": {
        "id": "RQ-WoAAzcDAx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}